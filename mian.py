
import streamlit as st
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
from langchain.llms import HuggingFaceHub
from langchain.chains import RetrievalQA
from langchain.document_loaders import TextLoader
import os

st.set_page_config(page_title="Ù…Ø³Ø§Ø¹Ø¯ Ø­Ù…Ø§ÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø´Ø®ØµÙŠØ©", page_icon="ğŸ›¡ï¸")

st.title("Ù…Ø³Ø§Ø¹Ø¯ Ù†Ø¸Ø§Ù… Ø­Ù…Ø§ÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø´Ø®ØµÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ")
st.write("Ø£Ø¯Ø®Ù„ Ø³Ø¤Ø§Ù„Ùƒ Ø­ÙˆÙ„ Ø§Ù„Ù†Ø¸Ø§Ù…ØŒ ÙˆØ³ÙŠØªÙ… Ø§Ù„Ø±Ø¯ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ Ø§Ù„Ø±Ø³Ù…ÙŠØ© ÙÙ‚Ø·.")

query = st.text_input("Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§:", "")

if query:
    with st.spinner("Ø¬Ø§Ø±Ù Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©..."):
        embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
        db = FAISS.load_local("vectorstore", embeddings)
        retriever = db.as_retriever(search_kwargs={"k": 3})
        llm = HuggingFaceHub(repo_id="mistralai/Mistral-7B-Instruct-v0.1", model_kwargs={"temperature":0.5, "max_new_tokens":512})
        qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)
        result = qa_chain.run(query)
        st.write("### Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:")
        st.write(result)
